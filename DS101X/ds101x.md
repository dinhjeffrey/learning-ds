#Confidence Interval
[Buffon's Needle](https://courses.edx.org/courses/course-v1:ColumbiaX+DS101X+1T2016/courseware/5c71f003d43e44b2b21a934df4dc6ca0/4e212e4f39e74b40ac9c1e1f36476d0a/?child=first)

Note the following: 
1. How the confidence intervals using 20 tosses differ from the confidence intervals based on 10 tosses?
The 20 tosses had a lower upper CI than the 10 tosses
2. How the confidence intervals change when you change the confidence level?
Lower CI goes up, Upper CI goes down - when you lower CI
Vice versa
3. How do the P-values change when you change the values of A and B?
When I lower B, the P value goes up. When I increase B, the P value goes down.
Vice versa for A.
4. How do the p-values in trials 1-5 differ from the p-values in trials 6-10?
The P values seem the same.

#Studying Association
1. (F) Two-way table summarizes join occurrences or values from any two variables.
<b>Only categorical variables</b>
2. (T) Two variables are said to be associated if certain combinations of values for the two variables occur more or less frequently than expected under independence
3. (F) Under the null hypothesis of independence, the probability of observing a given combination of values for the two variables is 1 divided by the number of possible combinations.
<b>...is divided by the marginal distribution.</b>
4. (T) Rejecting the null hypothesis of independence does not mean there is a strong association between X and Y.
<b>It only means that the association pattern between X and Y shown in the data is unlikely due to chance.</b>
5. (F) If a quantitative variable Y is independent with a categorical variable X, the distribution of Y for individuals with one value of X differs substantially from the distribution of Y for individuals with another value of X.
<b>The distribution of Y does not change with the value of X when Y is independent with X.
6. (T) Analysis of Variance is used to detect differences in the within-group mean of Y between groups defined by X.

#3h Regression Analysis 4 and Concluding Remarks
1. (F) The magnitude of regression coefficients is a good indicator of their importance.
<b>It depends on the scale of X variable.</b>
2. (F) The fitted regression line using a sample of data gives imperfect predictions for future observations due to only sampling variability.
<b>Due to sampling variability and randomness in Y that is not related to X.</b>
3. (T) Extrapolation is dangerous as the form of association between X and Y outside the range where the data were collected may be different from that within the range.

#3i Types of Data Analytics
##What's Your Problem?
<ul>
<li>methods determined by data and problem</li>
<li>possible FOMC questions:</li>
<ul>
<li>what topics were discussed?</li>
<b>Descriptive analytics - what is in our data</b>
<li>will interest rates be raised at the next meeting?</li>
<b>Predictive analytics - predict</b>
<li>how should I change my portfolio given the text of last meeting?</li>
<b>Prescriptive analytics - decide how to best allocate our resources</b>
</ul>
</ul>

##Descriptive Analytics: what is in your data?
<ul>
<li>simple metrics</li>
<li>entity lists</li>
<li>clustering</li>
<li>segmentation</li>
<li>dimension reduction</li>
<br>
<li>a good summary helps you ask better questions</li>
<li>who was there?</li>
<li>what topics were discussed?</li>
<li>how much were each discussed?</li>
<li>was the discussion positive or negative?</li>
<li>may also transform data into something for use in predictive or prescriptive analytics</li>
<li>words are not easy to model statistically, but word counts are (Document Term Matrix)</li>
<li>summarize with topics</li>
</ul>

##Predictive Analytics: what will the outcome be for a new input?
<li>classification</li>
<li>regression</li>
<li>point estimates vs. full distribution</li>

##Prescriptive: given the data, what action should I take?
<li>optimization</li>
<li>causal inference</li>

##3j Clustering Text
Stem and remove stopwords from the following: 
* “All happy families are alike; each unhappy family is unhappy in its own way.” 

<ul>
<li>all - 1</li>
<li>happy - 1</li>
<li>famil - 2</li>
<li>be - 2</li>
<li>alike - 1</li>
<li>each - 1</li>
<li>unhappy - 2</li>
<li>own - 1</li>
<li>way - 1</li>
</ul>

##3I Metrics for Label Description
Mean = -1 + 0 + 1 + 2 + 23 / 5 = 5

Median = -1, 0, 1, 2, 23 = 1

Squared error(Y,X) = (Y-X)*(Y-X)
Absolute error(Y,X) = |Y-X|

Squared Error for Mean:
* -1-5= -6
* -0-5= -5
* 1-5= -4
* 2-5= -3
* 23-5= 18
Square up each and add together = 410

Absolute Error for Mean:
Change each to positive and add together = 36

Squared Error for Median:
* -1-1 = -2
* 0-1= -1
* 1-1= 0
* 2-1= 1
* 23-1= 22
Square up each and add together = 490

Absolute Error for Median:
Change each to positive and add together = 26

##5a Intro to Bayesian Modeling
1. (T) The likelihood function is a function of the parameters.

2. (F) Posterior distribution reflects only info contained in the observed data.
- The posterior distribution reflects both prior belief and info in the data.

3. Bayesian inference is likelihood based.

4. Bayesian inference makes statements based on sampling distributions of estimates.
- Bayesian inference makes statements based on the posterior distribution, which is conditional probability distribution about unknown parameters given data.

5. Bayesian inference provides a good approximation of uncertainty about the unknown parameter.

##5d Assignment: Bayesian Inference

From a survey of 500 people, you estimate the proportion who support candidate A in the upcoming election to be 60%. The standard error for this estimate is 2%. From a previous forecast (not using this survey) you get a prediction that candidate A will win 51% of the vote, with the standard error of this forecast being 3% which accounts for both sampling variability and nonsampling errors. 

1. Using Bayesian method, the Bayesian posterior forecast combining the survey and the forcast is:
- The prior and data are weighted using inverse variance: { 0.6 * ( 1 / ( 0.02^2 ) ) + 0.51 * ( 1 / ( 0.03^2 ))} / { 1 / (0.02^2) + 1 / ( 0.03^2 ) } = 0.572 

